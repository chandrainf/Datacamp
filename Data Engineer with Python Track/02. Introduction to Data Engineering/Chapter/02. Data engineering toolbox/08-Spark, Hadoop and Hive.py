'''
Spark, Hadoop and Hive


You've encountered quite a few open source projects in the previous video. There's Hadoop, Hive, and PySpark. It's easy to get confused between these projects.

They have a few things in common: they are all currently maintained by the Apache Software Foundation, and they've all been used for massive parallel processing. Can you spot the differences?

Instructions
100XP

- Classify the cards to the corresponding software project.

'''
